{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a738dc-4409-4bd6-a33f-eab1d31dfbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import Model\n",
    "\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68bb1ec-f459-40bb-84df-5d80b7082094",
   "metadata": {},
   "source": [
    "# Lightning Library\n",
    "- It simplifies deep learning workflow with PyTorch\n",
    "- Less code & fewer bugs & better maintability\n",
    "- Excellent modularity\n",
    "- LightningModule & Trainer are the only 2 APIs, reset is organized\n",
    "### LightningModule\n",
    "- Easy to use any PyTorch model including LLM & Transformers etc.\n",
    "- Easy to use any sized datasets\n",
    "### Trainer\n",
    "- Scale models to trillions of parameters accross 1000s of GPUs\n",
    "- Compressing models with no accuracy loss with precision technics\n",
    "- Easy to define max_time & max_steps to save time & money\n",
    "- Easy to reproduce\n",
    "\n",
    "<img src=\"https://www.assemblyai.com/blog/content/images/2021/12/breakdown.png\" width=1000, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcc584-153b-4e1f-aaf5-542738f24168",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "### GPU enabled training\n",
    "- PyTorch\n",
    "  ```python \n",
    "  model.to(\"cuda\")\n",
    "  features.to(\"cuda\")\n",
    "  labels.to(\"cuda\")\n",
    "  ```\n",
    "- Lightning\n",
    "  ```python\n",
    "  # Train with 1 gpu\n",
    "  trainer = Trainer(accelerator=\"gpu\", devices=1, ...)\n",
    "  # Train with 4 gpu\n",
    "  trainer = Trainer(accelerator=\"gpu\", devices=4, ...)\n",
    "  # Train with 1st&3rd gpu\n",
    "  trainer = Trainer(accelerator=\"gpu\", devices=[0, 2], ...)\n",
    "  ```\n",
    "### Training Strategies\n",
    "- Data Parallel (multiple gpus, 1 machine)\n",
    "    ```python\n",
    "    Trainer(strategy='dp')\n",
    "    ```\n",
    "- Distrubuted Data Parallel (multiple gpus, many machines)\n",
    "    ```python\n",
    "    Trainer(strategy='ddp')\n",
    "    ```\n",
    "\n",
    "### Debugging\n",
    "- Controll running without training\n",
    "  ```python\n",
    "    # Runs only 1 training and 1 validation batch and the program ends\n",
    "    Trainer(fast_dev_run=True) \n",
    "    # Runs 7 training and 7 validation batch and the program ends\n",
    "    Trainer(fast_dev_run=7) \n",
    "    ```\n",
    "- Use this much of data\n",
    "  ```python\n",
    "    # Use only %1 of the train & val set\n",
    "    Trainer(overfit_batches=0.01)\n",
    "    # Use 10 of the same batches\n",
    "    Trainer(overfit_batches=10) \n",
    "    ```\n",
    "\n",
    "### I want to use Lightning Multi GPU & Mixed Precision Training but not want to restructure my code into LightningModule\n",
    "- Lightning Fabric\n",
    "    ```python\n",
    "    # Define fabric\n",
    "    fabric = Fabric(accelerator=\"gpu\", devices=64, strategy=\"ddp\")\n",
    "    # Set up model & optimizer & dataloaders\n",
    "    model, optimizer = fabric.setup(model, optimizer)\n",
    "    dataloader = fabric.set_dataloaders(dataloader)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataloader:\n",
    "            input, target = batch\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "            # loss.backward() -> fabric.backward(loss)\n",
    "            fabric.backward(loss)\n",
    "            optimizer.step()\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16552a0-7b58-4cd2-8a68-76ce3bcbe881",
   "metadata": {},
   "source": [
    "# Speed Comparison of Training DistilBERT\n",
    "<img src=\"https://sebastianraschka.com/images/blog/2023/pytorch-faster/benchmark-last.png\" width=\"1000\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29af23-b33a-45de-84ca-96760c1f01a2",
   "metadata": {},
   "source": [
    "# Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae88f67b-7cce-4dc9-bedc-4c63167a2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model, lr):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _common_step(self, batch):\n",
    "        images, true_labels = batch\n",
    "        logits = self(images)\n",
    "        loss = F.cross_entropy(logits, true_labels)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        return loss, predicted_labels, true_labels\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, predicted_labels, true_labels = self._common_step(batch)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.train_acc(predicted_labels, true_labels)\n",
    "        self.log(\"train_acc\", self.train_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, predicted_labels, true_labels = self._common_step(batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.val_acc(predicted_labels, true_labels)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, predicted_labels, true_labels = self._common_step(batch)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.test_acc(predicted_labels, true_labels)\n",
    "        self.log(\"test_acc\", self.test_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr = self.lr)\n",
    "        return optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880db29-a856-4889-a56d-46707412b0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remenv",
   "language": "python",
   "name": "remenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
